{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máltækni 2022, verkefni 5\n",
    "\n",
    "## 1) Forþjálfaðar, kyrrstæðar greypingar\n",
    "\n",
    "Í þessum hluta verkefnisins eigið þið að finna tvær af eftirfarandi forþjálfuðum, kyrrstæðum\n",
    "greypingum á netinu: word2vec, GloVe eða FastText. Notið þær til að leysa liðina hér fyrir\n",
    "neðan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Veljið 10 orð og finnið þau 5 orð sem líkönin meta sem svo að séu líkust þeim orðum\n",
    "(þau 5 orð sem eru með hæstu cosine similarity einkunn við orðin sem þið veljið,\n",
    "samtals 50 orð). Þrjú orðanna sem þið veljið eiga að vera sagnorð, þrjú lýsingarorð og\n",
    "fjögur nafnorð.\n",
    "\n",
    "Eru niðurstöðurnar eins og þið bjuggust við (þ.e. eru þessi orð raunverulega lík inntaksorðinu)?\n",
    "\n",
    "Hvers vegna/hvers vegna ekki?\n",
    "\n",
    "Er munur á niðurstöðum líkananna tveggja? Hvort stendur sig betur og hvers vegna haldið þið að það sé?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "  \"play\",\n",
    "  \"program\",\n",
    "  \"dance\",\n",
    "  \"big\",\n",
    "  \"blue\",\n",
    "  \"cute\",\n",
    "  \"house\",\n",
    "  \"dog\",\n",
    "  \"spoon\",\n",
    "  \"pen\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "# https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "corpus = api.load('text8')\n",
    "\n",
    "model = Word2Vec(corpus)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "['playing', 'plays', 'match', 'score', 'played']\n",
      "program\n",
      "['programs', 'package', 'project', 'programme', 'module']\n",
      "dance\n",
      "['dancing', 'ballroom', 'pop', 'techno', 'music']\n",
      "big\n",
      "['bang', 'muppet', 'lebowski', 'slim', 'tonight']\n",
      "blue\n",
      "['red', 'yellow', 'green', 'purple', 'velvet']\n",
      "cute\n",
      "['chow', 'daffy', 'marmalade', 'pumpkin', 'plum']\n",
      "house\n",
      "['commons', 'lords', 'palace', 'chamber', 'parliament']\n",
      "dog\n",
      "['cat', 'hound', 'ass', 'goat', 'cow']\n",
      "spoon\n",
      "['bamboo', 'skirt', 'strap', 'cake', 'whipped']\n",
      "pen\n",
      "['ballpoint', 'rhyme', 'serif', 'pencil', 'typewriter']\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w)\n",
    "    print([item[0] for item in model.wv.most_similar(w, topn=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext\n",
    "# https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "\n",
    "import fasttext.util\n",
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "['playing', 'plays', 'played', 'play.So', 'game', 'play.I', 'play.This', 'play.', 'play.Now', 'play.It']\n",
      "program\n",
      "['programs', 'progam', 'program.This', 'program.The', 'Program', 'progra', 'program.It', 'program.As', 'program.But', 'program.When']\n",
      "dance\n",
      "['dancing', 'dances', 'dance-', 'dance.The', 'dancers', 'dance.This', 'line-dance', 'dance.', 'Dance', 'dancer']\n",
      "big\n",
      "['huge', 'BIG', 'super-big', 'biiiig', 'HUGE', 'bigger', 'biiiiig', 'humongous', 'gigantic', 'not-so-big']\n",
      "blue\n",
      "['red', 'purple', 'yellow', 'pink', 'light-blue', 'green-blue', 'green', 'orange', 'blue-green', 'white']\n",
      "cute\n",
      "['adorable', 'CUTE', 'super-cute', 'Cute', 'ADORABLE', 'cuuuuute', 'cuuuuuute', 'cute--', 'cuuuute', 'oh-so-cute']\n",
      "house\n",
      "['hosue', 'houses', 'mansion', 'apartment', 'home', 'house.This', 'house-', 'house.But', 'house.The', 'house.When']\n",
      "dog\n",
      "['dogs', 'puppy', 'pup', 'canine', 'pet', 'doggie', 'dog--', 'beagle', 'dachshund', 'cat']\n",
      "spoon\n",
      "['spoons', 'spoon.', 'spoon.I', 'spoon.The', 'spoon-', 'ladle', 'spatula', 'soupspoon', 'spoonful', 'ladel']\n",
      "pen\n",
      "['pens', 'pen.The', 'pen.I', 'pen.', 'ballpoint', 'pencil', 'ball-point', 'fountain-pen', 'felt-tip', 'pen-']\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    print(w)\n",
    "    print([item[1] for item in ft.get_nearest_neighbors(w)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eru niðurstöðurnar eins og þið bjuggust við (þ.e. eru þessi orð raunverulega lík inntaksorðinu)?\n",
    "Hvers vegna/hvers vegna ekki?\n",
    "Er munur á niðurstöðum líkananna tveggja? Hvort stendur sig betur og hvers vegna haldið þið að það sé?\n",
    "\n",
    "Niðurstöður word2vec eru meira eins og ég bjóst við og líkari inntaksorðinu. M.v. að þjálfunarsett fyrir fasttext er yfir 7GB og textinn kemur frá netinu gegnum [Common Crawl](https://commoncrawl.org/) þá er hann „líkari“ hvernig fólk er að skrifa. T.d. að `ADORABLE` og `oh-so-cute` séu nálægt `cute`. Fyrir word2vec þá fáum við `chow` (??) og `marmalade`.\n",
    "\n",
    "Fasttext skilar líka skringilegum niðurstöðum fyrir `play`, `pen` og `house` með orðum sem innihalda punkt.\n",
    "\n",
    "word2vec settið er greinileg frekar breskt, með nágranna `house` vera tengda þinginu.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Látið líkönin svara 5 analógíuspurningum að eigin vali, á borð við kóngur - karl + kona =\n",
    "drottning. Gerið grein fyrir niðurstöðunum. Ná líkönin að svara spurningunum rétt? Í\n",
    "hversu mörgum tilfellum er rétta svarið með hæstu cosine similarity einkunn? Í hversu\n",
    "mörgum tilfellum er það ekki efst en þó í efstu 10 sætunum? Í hversu mörgum tilfellum\n",
    "finnst rétta svarið ekki? Hvað ætli valdi því?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# word2vec\n",
    "# https://towardsdatascience.com/how-to-solve-analogies-with-word2vec-6ebaf2354009\n",
    "# leit ekki út fyrir að vera jafn auðvelt að reikna með fasttext svo notum bara word2vec\n",
    "\n",
    "def w2v_analogy(model, base, negative, positive):\n",
    "    return model.most_similar(negative=[negative], positive=[base, positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7123323082923889),\n",
       " ('prince', 0.642742931842804),\n",
       " ('throne', 0.6405077576637268),\n",
       " ('princess', 0.6198208928108215),\n",
       " ('empress', 0.6167038679122925),\n",
       " ('emperor', 0.6116120219230652),\n",
       " ('son', 0.5972328782081604),\n",
       " ('daughter', 0.5934738516807556),\n",
       " ('elizabeth', 0.5906277298927307),\n",
       " ('mary', 0.5872237682342529)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fáum queen í fyrsta sæti, jákvætt merki\n",
    "w2v_analogy(model.wv, 'king', 'man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wingers', 0.513640284538269),\n",
       " ('ltte', 0.4704815745353699),\n",
       " ('insurgency', 0.46998876333236694),\n",
       " ('regime', 0.4664933383464813),\n",
       " ('nationals', 0.4633113443851471),\n",
       " ('rally', 0.4629363417625427),\n",
       " ('nationalists', 0.46198204159736633),\n",
       " ('chechnya', 0.4571993947029114),\n",
       " ('activist', 0.450588196516037),\n",
       " ('embassy', 0.4479149281978607)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# myndi gera ráð fyrir flugvél en kemur ekki í top 10, fáum skrítin orð tengd þjóðernisstefnu\n",
    "# lág einkunn\n",
    "w2v_analogy(model.wv, 'car', 'wheel', 'wing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jamaica', 0.5936331152915955),\n",
       " ('zambia', 0.5881912112236023),\n",
       " ('estonia', 0.5863310694694519),\n",
       " ('zimbabwe', 0.5826863646507263),\n",
       " ('burundi', 0.5806218385696411),\n",
       " ('andorra', 0.5794582962989807),\n",
       " ('kiribati', 0.5772671699523926),\n",
       " ('namibia', 0.5767364501953125),\n",
       " ('faso', 0.5720131993293762),\n",
       " ('tanzania', 0.5668596029281616)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meikar sens að fá grænland hér? Jamaica er samt ekki slæm niðurstaða\n",
    "# lág einkunn en samt í áttina?\n",
    "w2v_analogy(model.wv, 'iceland', 'ice', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harpo', 0.6694238781929016),\n",
       " ('imitating', 0.6482334733009338),\n",
       " ('melodramatic', 0.625411868095398),\n",
       " ('mcdermott', 0.6226817965507507),\n",
       " ('courageous', 0.6223416924476624),\n",
       " ('kfc', 0.6160545349121094),\n",
       " ('fatboy', 0.6031714081764221),\n",
       " ('gwen', 0.6019134521484375),\n",
       " ('stuntman', 0.600668728351593),\n",
       " ('carrey', 0.5993795394897461)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lol, meikar ekkert sens, hér er stærð módels farið að sjást\n",
    "w2v_analogy(model.wv, 'zombie', 'dead', 'alive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meat', 0.752078115940094),\n",
       " ('milk', 0.726511538028717),\n",
       " ('eating', 0.7018194794654846),\n",
       " ('tobacco', 0.6980304718017578),\n",
       " ('drink', 0.6976299285888672),\n",
       " ('coffee', 0.6862428188323975),\n",
       " ('beef', 0.6790598630905151),\n",
       " ('beans', 0.6667898297309875),\n",
       " ('vegetables', 0.6662499904632568),\n",
       " ('tea', 0.6655742526054382)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sammála\n",
    "w2v_analogy(model.wv, 'food', 'good', 'bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('compiler', 0.5746666789054871),\n",
       " ('scripting', 0.5663358569145203),\n",
       " ('haskell', 0.5626983046531677),\n",
       " ('perl', 0.5608559250831604),\n",
       " ('sound', 0.5436562299728394),\n",
       " ('assembler', 0.5431581735610962),\n",
       " ('lisp', 0.5306848883628845),\n",
       " ('ide', 0.5260365605354309),\n",
       " ('directx', 0.5205888152122498),\n",
       " ('interpreter', 0.5176267027854919)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hmmm\n",
    "w2v_analogy(model.wv, 'programming', 'science', 'art')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Forþjálfaðar, samhengisháðar greypingar\n",
    "\n",
    "Í þessum hluta verkefnisins notið þið IceBERT frá Miðeind til þess að leysa eftirfarandi liði."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Veljið 10 setningar og felið (mask) eitt orð úr hverri setningu. Eru svörin frá IceBERT í samræmi við það sem þið hélduð? Hvers vegna/hvers vegna ekki? Fjallið um röng svör út frá málvísindalegu sjónarhorni. Eru þau til dæmis samheiti eða andheiti við rétta svarið? Eru þau innan þess merkingarfræðilega sviðs eða ramma sem þið hefðuð búist við?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaForMaskedLM, RobertaTokenizer\n",
    "MODEL_NAME = \"mideind/IceBERT\"\n",
    "r_tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "r_model = RobertaForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def ask_icebert(q):\n",
    "    input = r_tokenizer(q, return_tensors = \"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "      logits = r_model(**input).logits\n",
    "    mask_token_index = (input.input_ids == r_tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "    predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "    \n",
    "    return tokenizer.decode(predicted_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' borða'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# þetta amk virkar!\n",
    "ask_icebert(\"Má bjóða þér eitthvað að <mask> ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hann'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kynjahalli?\n",
    "ask_icebert(\"<mask> er frábær\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' vera'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IceBERT er óákveðið\n",
    "ask_icebert(\"Stundum þarf bara að <mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' vera'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IceBERT en hverju breytir upphrópunarmerkið?\n",
    "ask_icebert(\"Stundum þarf bara að <mask>!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' það'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IceBERT er ekki hjálplegt í að svara stóru spurningum hversdagsins.\n",
    "ask_icebert(\"Við skulum hafa <mask> í kvöldmatinn á morgun.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " stór\n",
      " læknir\n",
      " sjómaður\n"
     ]
    }
   ],
   "source": [
    "# Munur á greinarmerki\n",
    "print(ask_icebert(\"Þegar ég verð stór ætla ég að verða <mask>.\"))\n",
    "print(ask_icebert(\"Þegar ég verð stór ætla ég að verða <mask>?\"))\n",
    "print(ask_icebert(\"Þegar ég verð stór ætla ég að verða <mask>!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Það ekki dag'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Virkar að setja nokkra maska?\n",
    "ask_icebert(\"<mask> er <mask> í <mask>!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hvað heimi'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lítur út fyrir það!\n",
    "ask_icebert(\"<mask> er best í <mask>?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' talar'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hér er eitthvað í ruglinu\n",
    "ask_icebert(\"Sakar <mask> um að svindla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Höfundur\n",
      " Hver\n",
      " Hann\n"
     ]
    }
   ],
   "source": [
    "# Aftur mikill munur á greinarmerki\n",
    "print(ask_icebert(\"<mask> hyggst láta af störfum\"))\n",
    "print(ask_icebert(\"<mask> hyggst láta af störfum?\"))\n",
    "print(ask_icebert(\"<mask> hyggst láta af störfum!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fag'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einmitt!\n",
    "ask_icebert(\"Máltækni er <mask>.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (Bónus) Finnið þið bjaga í niðurstöðunum? Hvers eðlis er bjaginn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greinarmerki virðist hafa tiltölulega mikil áhrif á hvað er skilað"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Ykkar eigin, kyrrstæðu greypingar\n",
    "\n",
    "Í þessum hluta verkefnisins eigið þið að þjálfa ykkar eigin kyrrstæðu greypingalíkön og nota til þess gögnin sem þið söfnuðuð í 1. hluta 2. verkefnis. Athugið að 20.000 orða gagnasafn er mjög lítið og það mun koma til með að hafa (verulega) neikvæð áhrif á niðurstöðurnar ykkar.\n",
    "Því stærra sem gagnasafnið er sem þið notið, því líklegra er að þið fáið góðar niðurstöður en þjálfunin mun á hinn bóginn taka lengri tíma og hugsanlega meira tölvuafl. Ykkur er frjálst að nota stærra gagnasafn en það sem þið söfnuðuð ef þið viljið en það er ekki krafa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Veljið annað hvort word2vec, GloVe eða FastText og þjálfið það á gagnasafninu ykkar.\n",
    "Þið megið nota hvaða forritasafn sem þið viljið til þess (við mælum með Gensim). Gerið svo eftirfarandi:\n",
    "a) Þjálfið líkanið á gögnunum óbreyttum.\n",
    "\n",
    "2. Gerið sömu tilraunir og í fyrsta hluta verkefnisins og berið saman niðurstöðurnar eftir því hvort inntaksgögnin eru forunnin eða ekki. Það er mjög líklegt að þið fáið niðurstöður sem eru tiltölulega út í hött ef gagnasafnið ykkar er lítið. Gerið nokkrar tilraunir með að fikta í yfirbreytunum (hyperparameters). Gerið grein fyrir helstu niðurstöðum, hvaða breytu(m) þið breyttuð og hvort það varð til þess að bæta eða skekkja niðurstöðurnar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceIterator: \n",
    "    def __init__(self, filepath): \n",
    "        self.filepath = filepath \n",
    "\n",
    "    def __iter__(self): \n",
    "        for line in open(self.filepath): \n",
    "            yield line.split() \n",
    "\n",
    "raw_sentences = SentenceIterator(\"./data/pride-and-prejudice.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "['Wickham’s', 'whether', 'then', 'father', 'To']\n",
      "program\n",
      "orð fannst ekki\n",
      "dance\n",
      "['enough', 'back', 'even', 'often', 'that,']\n",
      "big\n",
      "orð fannst ekki\n",
      "blue\n",
      "orð fannst ekki\n",
      "cute\n",
      "orð fannst ekki\n",
      "house\n",
      "['They', 'every', 'and,', 'again', 'most']\n",
      "dog\n",
      "orð fannst ekki\n",
      "spoon\n",
      "orð fannst ekki\n",
      "pen\n",
      "orð fannst ekki\n",
      "[('far', 0.9814496636390686), ('easily', 0.9809041023254395), ('speak', 0.9807381629943848), ('what', 0.9806647300720215), ('see', 0.9806087613105774), ('“You', 0.9806084036827087), ('all.', 0.9803667068481445), ('feel', 0.9803217053413391), ('nothing', 0.9802998304367065), ('quite', 0.9802988767623901)]\n"
     ]
    }
   ],
   "source": [
    "# Notum word2vec\n",
    "\n",
    "raw_w2v_model = Word2Vec(\n",
    "    sentences=raw_sentences,\n",
    "    #vector_size=100,\n",
    "    window=10,\n",
    "    min_count=3,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "for w in words:\n",
    "    print(w)\n",
    "    try:\n",
    "        print([item[0] for item in raw_w2v_model.wv.most_similar(w, topn=5)])\n",
    "    except:\n",
    "        print(\"orð fannst ekki\")\n",
    "\n",
    "try:\n",
    "    print(w2v_analogy(raw_w2v_model.wv, 'dance', 'play', 'sad'))\n",
    "except:\n",
    "    print(\"Gat ekki reiknað\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fáum afskaplega lítið til baka, gat ekki reiknað neinar af fyrrir analógum.\n",
    "\n",
    "Breytingar á yfirbreytum gerði ekki mikið til að bæta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Þjálfið líkanið á gögnunum eftir að hafa lemmað þau og fjarlægt stopporð."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "with open(\"./data/stopwords-en.txt\", \"rb\") as input_file:\n",
    "    en_stop_words = input_file.read().decode(\"utf8\").split()\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "class SentenceIterator2: \n",
    "    def __init__(self, filepath): \n",
    "        self.filepath = filepath \n",
    "\n",
    "    def __iter__(self): \n",
    "        for line in open(self.filepath):\n",
    "            lemmas = [wnl.lemmatize(word) for word in line.split()]\n",
    "            yield [word for word in lemmas if word.lower() not in en_stop_words]\n",
    "\n",
    "lemma_no_stops_sentences = SentenceIterator2(\"./data/pride-and-prejudice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n",
      "['hear', 'without', 'week', 'him.', 'long']\n",
      "program\n",
      "orð fannst ekki\n",
      "dance\n",
      "['her,', 'letter', 'young', 'look', 'asked']\n",
      "big\n",
      "orð fannst ekki\n",
      "blue\n",
      "orð fannst ekki\n",
      "cute\n",
      "orð fannst ekki\n",
      "house\n",
      "['must', 'soon', 'may', 'think', 'one']\n",
      "dog\n",
      "orð fannst ekki\n",
      "spoon\n",
      "orð fannst ekki\n",
      "pen\n",
      "orð fannst ekki\n",
      "[('“When', 0.9469315409660339), ('feared', 0.94669109582901), ('respect', 0.9466426968574524), ('but,', 0.9465564489364624), ('expected', 0.9460793733596802), ('happiness', 0.9459971189498901), ('bring', 0.9458485841751099), ('engagement', 0.9458281993865967), ('thank', 0.9457820653915405), ('except', 0.9457477331161499)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lemma_w2v_model = Word2Vec(\n",
    "    sentences=lemma_no_stops_sentences,\n",
    "    vector_size=100,\n",
    "    window=10,\n",
    "    min_count=3,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "for w in words:\n",
    "    print(w)\n",
    "    try:\n",
    "        print([item[0] for item in lemma_w2v_model.wv.most_similar(w, topn=5)])\n",
    "    except:\n",
    "        print(\"orð fannst ekki\")\n",
    "\n",
    "try:\n",
    "    print(w2v_analogy(lemma_w2v_model.wv, 'dance', 'play', 'sad'))\n",
    "except:\n",
    "    print(\"Gat ekki reiknað\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voðalega svipað.. alls ekki góðar niðurstöður. Að eiga við breytur breytti ekki miklu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae2e14ec575573b8be072e4f3a87b89fe042cbcbb9ac3447dde126ec4009b8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
